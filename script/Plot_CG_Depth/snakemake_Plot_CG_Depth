####Dry RUN command :
#nohup snakemake -j 150 -s snakemake_Plot_CG_Depth --rerun-incomplete -n --cluster "sbatch -J {params.name} -p {params.partition} -t {params.time} --mem {params.mem} --cpus-per-task {params.threads} -o {params.out} -e {params.err} --exclude=pbil-deb[14-27] " &> nohup_snakemake_Plot_CG_Depth &
####Unlock command :
#nohup snakemake -j 50 -s snakemake_Plot_CG_Depth --unlock --cluster "sbatch -J {params.name} -p {params.partition} -t {params.time} --mem {params.mem} --cpus-per-task {params.threads} -o {params.out} -e {params.err} --exclude=pbil-deb[14-27] "  &> nohup_snakemake_Plot_CG_Depth &
####Real command :
#nohup snakemake -j 50 -s snakemake_Plot_CG_Depth --cluster "sbatch -J {params.name} -p {params.partition} -t {params.time} --mem {params.mem} --cpus-per-task {params.threads} -o {params.out} -e {params.err} --exclude=pbil-deb[14-27] " &> nohup_snakemake_Plot_CG_Depth &

####marqué les fichier comme completer en cas de changement de params :
#snakemake -j 150 -s snakemake_Plot_CG_Depth --touch


import re
import os

#paths
bin_dir="/beegfs/project/horizon/bin/miniconda3/bin/"   #bin du projet horizon où se trouvent les programmes
scripts_dir="/beegfs/data/fblanchard/horizon/script/Plot_CG_Depth/"   #où se trouvent les scripts appelés
logs_dir="/beegfs/data/fblanchard/horizon/logs/Plot_CG_Depth/"   #où vont les logs de chaque script
#lists_dir="/beegfs/data/fblanchard/horizon/list/"   #où sont les listes
genomes_dir="/beegfs/data/fblanchard/horizon/genome/"   #où se trouvent les fasta des génomes des espèces
output_dir="/beegfs/data/fblanchard/horizon/Plot_CG_Depth/"  
Ss_ref_dir="/beegfs/project/horizon/data/assembly/Species_specimens_reference_genome.txt" #list du specimen de reférence pour chaque espece 
preds_dir="/beegfs/data/fblanchard/horizon/Genes_prediction/"  
Ss2_ref_dir="/beegfs/project/horizon/data/assembly/Species_specimen2.txt" #list du specimen 2 pour chaque espece 
TE_dir="/beegfs/project/horizon/data/TE/"
db="/beegfs/data/fblanchard/horizon/db/"

#species_list
#species_file = open('/beegfs/data/fblanchard/horizon/list/species_horizon_list.txt', 'r') #write the list
species_file = open('/beegfs/data/fblanchard/horizon/list/xiphosomella_wirra.txt', 'r') #write the list
# read the content and split when newline 
list_species = species_file.read().split('\n') 
list_species = list_species[:-1] 



# Load genome sizes from genome_sizes.tsv
genome_sizes = {}
with open("/beegfs/data/fblanchard/horizon/list/genome_sizes.tsv") as f:
    for line in f:
        species, size = line.strip().split()
        genome_sizes[species] = int(size)  # Taille en Mo




rule all:
        input:
                #rule calcul_taux_CG
                expand(output_dir+"{species}/{species}_taux_CG.tsv", species = list_species),

                #rule calculate_median
                expand(output_dir+"{species}/{species}_median_depth.tsv", species = list_species),

                #rule calculate_median_indiv2
                expand(output_dir+"{species}/{species}_median_depth_2.tsv", species = list_species),

                #rule clean_taxo
                expand(output_dir+"{species}/{species}_clean_taxo.tsv", species = list_species),

                #rule Plot_CG_depth
                expand(output_dir+"{species}/{species}_CG_plot.svg", species = list_species),
                expand(output_dir+"{species}/{species}_CG_plot.jpg", species = list_species),
                expand(output_dir+"{species}/{species}_Full_tab.tsv", species = list_species),

                #rule Krona
                expand(output_dir+"{species}/{species}_Krona.html", species = list_species),
                expand(output_dir+"{species}/{species}_Taxo_resume.tsv", species = list_species),

                #rule Tab_cds
                expand(output_dir+"{species}/{species}_Tab_cds.tsv",species = list_species),

                #rule GO_finder
                expand(output_dir+"{species}/{species}_Tab_cds_GO.tsv",species = list_species)


rule calcul_taux_CG:   
        params:
                name="calcul_taux_CG_{species}",
                out=logs_dir+"calcul_taux_CG/CG_{species}.out",
                err=logs_dir+"calcul_taux_CG/CG_{species}.error",
                partition="normal",
                threads="8",
                time="1:20:00",
                mem="10G"
        input:
                genome=genomes_dir+"{species}.fa"   
        output:
                CG=output_dir+"{species}/{species}_taux_CG.tsv"
        shell:
                """
                mkdir -p {output_dir}{wildcards.species}/
                {scripts_dir}cg_content_calculator.py {input.genome} {output.CG}
                """


rule clean_taxo:   
        params:
                name="clean_taxo_{species}",
                out=logs_dir+"clean_taxo/clean_taxo_{species}.out",
                err=logs_dir+"clean_taxo/clean_taxo_{species}.error",
                partition="normal",
                threads="8",
                time="2:00:00",
                mem="20G"
        input:
                taxResult=preds_dir+"{species}/{species}_taxResult_tax_per_contig.tsv"  
        output:
                clean_taxo=output_dir+"{species}/{species}_clean_taxo.tsv"
        shell:
                """
                /beegfs/home/fblanchard/miniconda3/bin/python3.12 {scripts_dir}taxo_clean.py \
                -i {input.taxResult} \
                -o {output.clean_taxo}
                """


rule calculate_median:
        params:
                name="calcul_median_depth_{species}",
                out=logs_dir + "median_depth/median_{species}.out",
                err=logs_dir + "median_depth/median_{species}.error",
                partition=lambda wildcards: "bigmem" if genome_sizes.get(wildcards.species, 0) > 600 else "normal",
                threads=8,
                time=lambda wildcards: "4:00:00" if genome_sizes.get(wildcards.species, 0) > 600 else "2:00:00",
                mem=lambda wildcards: "160G" if genome_sizes.get(wildcards.species, 0) > 600 else "80G"
    
        input:
                input=Ss_ref_dir

        output:
                output=output_dir+"{species}/{species}_median_depth.tsv"
        
        shell:
                """
                indiv=$(awk -v spc={wildcards.species} '$1==spc {{print $2}}' {input})

        
                zcat /beegfs/project/horizon/data/mapping/bed/{wildcards.species}:$indiv\.per-base.bed.gz | awk -F'\\t' '{{
                        split($1, scaffold_size, "|");
                        scaffold = scaffold_size[1];
                        size = scaffold_size[2];
                        data[scaffold "|" size][count[scaffold "|" size]++] = $3;
                }} 
                END {{
                        for (s in data) {{
                                n = count[s];
                                asort(data[s]);
                                if (n % 2 == 0) {{
                                        median = (data[s][n/2] + data[s][n/2 + 1]) / 2;
                                }} else {{
                                        median = data[s][(n+1)/2];
                                }}
                                print s, median;
                        }}
                }}' OFS='\\t' > {output}
                """

rule calculate_median_indiv2:
        params:
                name="calcul_median_depth_2_{species}",
                out=logs_dir + "median_depth/median_{species}_2.out",
                err=logs_dir + "median_depth/median_{species}_2.error",
                partition=lambda wildcards: "bigmem" if genome_sizes.get(wildcards.species, 0) > 600 else "normal",
                threads=8,
                time=lambda wildcards: "4:00:00" if genome_sizes.get(wildcards.species, 0) > 600 else "2:00:00",
                mem=lambda wildcards: "160G" if genome_sizes.get(wildcards.species, 0) > 600 else "80G"
            
        input:
                input=Ss2_ref_dir
        
        output:
                output=output_dir+"{species}/{species}_median_depth_2.tsv"
                
        shell:
                """
                indiv=$(awk -v spc={wildcards.species} '$1==spc {{print $2}}' {input})
        
                
                zcat /beegfs/project/horizon/data/mapping/bed/{wildcards.species}:$indiv\.per-base.bed.gz | awk -F'\\t' '{{
                        split($1, scaffold_size, "|");
                        scaffold = scaffold_size[1];
                        size = scaffold_size[2];
                        data[scaffold "|" size][count[scaffold "|" size]++] = $3;
                }} 
                END {{
                        for (s in data) {{
                                n = count[s];
                                asort(data[s]);
                                if (n % 2 == 0) {{
                                        median = (data[s][n/2] + data[s][n/2 + 1]) / 2;
                                }} else {{
                                        median = data[s][(n+1)/2];
                                }}
                                print s, median;
                        }}
                }}' OFS='\\t' > {output}
                """



rule Plot_CG_depth:   
        params:
                name="Plot_CG_depth_{species}",
                out=logs_dir+"Plot/Plot_CG_depth_{species}.out",
                err=logs_dir+"Plot/Plot_CG_depth_{species}.error",
                partition="normal",
                threads="8",
                time=lambda wildcards: "0:30:00" if genome_sizes.get(wildcards.species, 0) > 600 else "0:10:00",
                mem=lambda wildcards: "30G" if genome_sizes.get(wildcards.species, 0) > 600 else "10G"
        input:
                input_Ss=Ss_ref_dir,
                input_Ss2=Ss2_ref_dir,
                clean_taxo=output_dir+"{species}/{species}_clean_taxo.tsv",
                CG=output_dir+"{species}/{species}_taux_CG.tsv",
                depth=output_dir+"{species}/{species}_median_depth.tsv",
                depth_2=output_dir+"{species}/{species}_median_depth_2.tsv",
                TE=TE_dir+"{species}/result_mmseqs2.m8"
        output:
                Plot=output_dir+"{species}/{species}_CG_plot.svg",
                Plot_jpg=output_dir+"{species}/{species}_CG_plot.jpg",
                Full_tab=output_dir+"{species}/{species}_Full_tab.tsv"
        shell:
                """
                indiv=$(awk -v spc={wildcards.species} '$1==spc {{print $2}}' {input.input_Ss})  
                indiv2=$(awk -v spc={wildcards.species} '$1==spc {{print $2}}' {input.input_Ss2})
                

                /beegfs/data/soft/R-4.3.1/bin/Rscript {scripts_dir}Plot.R \
                --input_taxResult {input.clean_taxo} \
                --input_cov /beegfs/project/horizon/data/mapping/cov/{wildcards.species}\:${{indiv}}.cov \
                --input_cov_2 /beegfs/project/horizon/data/mapping/cov/{wildcards.species}\:${{indiv2}}.cov \
                --input_CG {input.CG} \
                --input_Busco /beegfs/project/horizon/data/stats/busco/specimens/${{indiv}}/run_insecta_odb10/full_table.tsv \
                --input_depth {input.depth} \
                --input_depth_2 {input.depth_2} \
                --input_TE {input.TE} \
                --output_Plot {output.Plot} \
                --output_Plot_jpg {output.Plot_jpg} \
                --output_full_tab {output.Full_tab}
                """

rule Krona:   
        params:
                name="Krona_{species}",
                out=logs_dir+"Krona/Krona_{species}.out",
                err=logs_dir+"Krona/Krona_{species}.error",
                partition="normal",
                threads="4",
                time="0:10:00",
                mem="8G"
        input:
                Full_tab=output_dir+"{species}/{species}_Full_tab.tsv"
        output:
                Krona=output_dir+"{species}/{species}_Krona.html",
                Taxo_resume=output_dir+"{species}/{species}_Taxo_resume.tsv"
        shell:
                """
                {scripts_dir}Krona.py {input.Full_tab} {output.Krona} {output.Taxo_resume}

                """


rule Tab_cds:   
        params:
                name="Tab_cds_{species}",
                out=logs_dir+"Tab_cds/Tab_cds_{species}.out",
                err=logs_dir+"Tab_cds/Tab_cds_{species}.error",
                partition="normal",
                threads="8",
                time="2:00:00",
                mem="16G"
        input:
                cds_preds=preds_dir+"{species}/{species}_taxResult_tax_per_pred.tsv"
        output:
                Tab_cds=output_dir+"{species}/{species}_Tab_cds.tsv",
                Tab_temp=output_dir+"{species}/{species}_Tab_temp.tsv"
        shell:
                """
                /beegfs/home/fblanchard/miniconda3/bin/python3.12 taxo_clean.py -i {input.cds_preds} -o {output.Tab_temp} 
                /beegfs/data/soft/R-4.3.1/bin/Rscript {scripts_dir}Tab_cds.R \
                --input_Temp {output.Tab_temp}  \
                --output_cds {output.Tab_cds} \
                """

rule GO_finder:   
        params:
                name="GO_finder_{species}",
                out=logs_dir+"GO_finder/GO_finder_{species}.out",
                err=logs_dir+"GO_finder/GO_finder_{species}.error",
                partition="normal",
                threads="8",
                time="2:00:00",
                mem="16G"
        input:
                Tab_cds=output_dir+"{species}/{species}_Tab_cds.tsv",
                idmapping=db+"idmapping_selected.tab"

        output:
                Tab_cds_GO=output_dir+"{species}/{species}_Tab_cds_GO.tsv",
                
        shell:
                """
                {scripts_dir}GO_finder.py {input.Tab_cds} {input.idmapping} {output.Tab_cds_GO}
                """